{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorhac/UnsupervisedMT/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "p1UBWMBcPLhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e1d8784-97e7-48fa-c0d2-1fc45aa7bc18"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dorhac/UnsupervisedMT.git\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'UnsupervisedMT' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZzSFog5iXD7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7ae966a0-6fe7-4154-a02f-896d482f1714"
      },
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)   \u001b[K\rremote: Counting objects:  28% (2/7)   \u001b[K\rremote: Counting objects:  42% (3/7)   \u001b[K\rremote: Counting objects:  57% (4/7)   \u001b[K\rremote: Counting objects:  71% (5/7)   \u001b[K\rremote: Counting objects:  85% (6/7)   \u001b[K\rremote: Counting objects: 100% (7/7)   \u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  25% (1/4)   \u001b[K\rremote: Compressing objects:  50% (2/4)   \u001b[K\rremote: Compressing objects:  75% (3/4)   \u001b[K\rremote: Compressing objects: 100% (4/4)   \u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/dorhac/UnsupervisedMT\n",
            "   ca241d8..403de60  master     -> origin/master\n",
            "Updating ca241d8..403de60\n",
            "Fast-forward\n",
            " NMT/get_data_enfr.sh | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OfolOReAP1U6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqGeMl5lRVSV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2380
        },
        "outputId": "3e0e1f7a-7d5b-4c83-a2b4-f4d1fa4d3cc7"
      },
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "chmod u+x ./get_data_enfr.sh\n",
        "./get_data_enfr.sh"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Moses found in: /content/new/UnsupervisedMT/NMT/tools/mosesdecoder\n",
            "fastBPE found in: /content/new/UnsupervisedMT/NMT/tools/fastBPE\n",
            "fastBPE compiled in: /content/new/UnsupervisedMT/NMT/tools/fastBPE/fast\n",
            "fastText found in: /content/new/UnsupervisedMT/NMT/tools/fastText\n",
            "fastText compiled in: /content/new/UnsupervisedMT/NMT/tools/fastText/fasttext\n",
            "Downloading English files...\n",
            "Downloading French files...\n",
            "1591854\n",
            "1591854\n",
            "EN monolingual data tokenized in: /content/new/UnsupervisedMT/NMT/data/mono/all.en.tok\n",
            "FR monolingual data tokenized in: /content/new/UnsupervisedMT/NMT/data/mono/all.fr.tok\n",
            "BPE learned in /content/new/UnsupervisedMT/NMT/data/mono/bpe_codes\n",
            "BPE codes applied to EN in: /content/new/UnsupervisedMT/NMT/data/mono/all.en.tok.60000\n",
            "BPE codes applied to FR in: /content/new/UnsupervisedMT/NMT/data/mono/all.fr.tok.60000\n",
            "EN vocab in: /content/new/UnsupervisedMT/NMT/data/mono/vocab.en.60000\n",
            "FR vocab in: /content/new/UnsupervisedMT/NMT/data/mono/vocab.fr.60000\n",
            "Full vocab in: /content/new/UnsupervisedMT/NMT/data/mono/vocab.en-fr.60000\n",
            "EN binarized data in: /content/new/UnsupervisedMT/NMT/data/mono/all.en.tok.60000.pth\n",
            "FR binarized data in: /content/new/UnsupervisedMT/NMT/data/mono/all.fr.tok.60000.pth\n",
            "Downloading parallel data...\n",
            "--2019-03-07 18:31:16--  http://data.statmt.org/wmt17/translation-task/dev.tgz\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Extracting parallel data...\n",
            "Tokenizing valid and test data...\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: fr\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 48\n",
            "Tokenizer Version 1.1\n",
            "Language: fr\n",
            "Number of threads: 48\n",
            "Applying BPE to valid and test files...\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/mono/vocab.en.60000 ...\n",
            "Read 11916490 words (54997 unique) from vocabulary file.\n",
            "Loading codes from /content/new/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.en ...\n",
            "Read 64812 words (9678 unique) from text file.\n",
            "Applying BPE to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.en ...\n",
            "Modified 64812 words from text file.\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/mono/vocab.fr.60000 ...\n",
            "Read 14814392 words (58405 unique) from vocabulary file.\n",
            "Loading codes from /content/new/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.fr ...\n",
            "Read 73672 words (11057 unique) from text file.\n",
            "Applying BPE to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.fr ...\n",
            "Modified 73672 words from text file.\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/mono/vocab.en.60000 ...\n",
            "Read 11916490 words (54997 unique) from vocabulary file.\n",
            "Loading codes from /content/new/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.en ...\n",
            "Read 71150 words (10609 unique) from text file.\n",
            "Applying BPE to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.en ...\n",
            "Modified 71150 words from text file.\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/mono/vocab.fr.60000 ...\n",
            "Read 14814392 words (58405 unique) from vocabulary file.\n",
            "Loading codes from /content/new/UnsupervisedMT/NMT/data/mono/bpe_codes ...\n",
            "Read 60000 codes from the codes file.\n",
            "Loading vocabulary from /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.fr ...\n",
            "Read 81104 words (11722 unique) from text file.\n",
            "Applying BPE to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.fr ...\n",
            "Modified 81104 words from text file.\n",
            "Binarizing data...\n",
            "INFO - 03/07/19 18:31:20 - 0:00:00 - Read 59867 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.en.60000.pth ...\n",
            "INFO - 03/07/19 18:31:20 - 0:00:00 - 73141 words (59867 unique) in 3000 sentences.\n",
            "INFO - 03/07/19 18:31:20 - 0:00:00 - 15 unknown words (4 unique), covering 0.02% of the data.\n",
            "INFO - 03/07/19 18:31:20 - 0:00:00 - ó@@: 8\n",
            "INFO - 03/07/19 18:31:20 - 0:00:00 - í@@: 3\n",
            "INFO - 03/07/19 18:31:20 - 0:00:00 - á@@: 3\n",
            "INFO - 03/07/19 18:31:20 - 0:00:00 - ê@@: 1\n",
            "INFO - 03/07/19 18:31:21 - 0:00:00 - Read 59867 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.fr.60000.pth ...\n",
            "INFO - 03/07/19 18:31:21 - 0:00:00 - 119232 words (59867 unique) in 3000 sentences.\n",
            "INFO - 03/07/19 18:31:21 - 0:00:00 - 1257 unknown words (36 unique), covering 1.05% of the data.\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - Read 59867 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.en.60000.pth ...\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - 81330 words (59867 unique) in 3003 sentences.\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - 24 unknown words (7 unique), covering 0.03% of the data.\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - â@@: 9\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - ô@@: 7\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - ê@@: 3\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - É@@: 2\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - à@@: 1\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - €: 1\n",
            "INFO - 03/07/19 18:31:22 - 0:00:00 - ë@@: 1\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - Read 59867 words from the vocabulary file.\n",
            "\n",
            "Saving the data to /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.fr.60000.pth ...\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - 135087 words (59867 unique) in 3003 sentences.\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - 1235 unknown words (13 unique), covering 0.91% of the data.\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - ê@@: 496\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - ô@@: 202\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - É@@: 144\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - â@@: 116\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - ù: 91\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - î@@: 88\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - À: 27\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - œ@@: 23\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - ë@@: 15\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - û: 11\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - Ç@@: 11\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - à@@: 10\n",
            "INFO - 03/07/19 18:31:23 - 0:00:00 - È@@: 1\n",
            "\n",
            "===== Data summary\n",
            "Monolingual training data:\n",
            "    EN: /content/new/UnsupervisedMT/NMT/data/mono/all.en.tok.60000.pth\n",
            "    FR: /content/new/UnsupervisedMT/NMT/data/mono/all.fr.tok.60000.pth\n",
            "Parallel validation data:\n",
            "    EN: /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.en.60000.pth\n",
            "    FR: /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2013-ref.fr.60000.pth\n",
            "Parallel test data:\n",
            "    EN: /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.en.60000.pth\n",
            "    FR: /content/new/UnsupervisedMT/NMT/data/para/dev/newstest2014-fren-src.fr.60000.pth\n",
            "\n",
            "Concatenated data in: /content/new/UnsupervisedMT/NMT/data/mono/all.en-fr.60000\n",
            "Training fastText on /content/new/UnsupervisedMT/NMT/data/mono/all.en-fr.60000...\n",
            "Read 29M words\n",
            "Number of words:  59854\n",
            "Number of labels: 0\n",
            "tcmalloc: large alloc 4218585088 bytes == 0x560c89a30000 @  0x7fb7e8160887 0x560c80c6d29d 0x560c80c77c98 0x560c80c7f044 0x560c80c84db2 0x560c80c4fd67 0x7fb7e71fdb97 0x560c80c5002a\n",
            "Progress: 100.0% words/sec/thread:     291 lr:  0.000000 loss:  2.454877 ETA:   0h 0m\n",
            "Cross-lingual embeddings in: /content/new/UnsupervisedMT/NMT/data/mono/all.en-fr.60000.vec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Fcx94rCdkfJq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2995
        },
        "outputId": "e3272820-9458-49ed-9158-c5a71f8925ad"
      },
      "cell_type": "code",
      "source": [
        "! printf 'y\\ny\\ny\\n' | python main.py --exp_name test --transformer True --n_enc_layers 4 --n_dec_layers 4 --share_enc 3 --share_dec 3 --share_lang_emb True --share_output_emb True --langs 'en,fr' --n_mono -1 --mono_dataset 'en:./data/mono/all.en.tok.60000.pth,,;fr:./data/mono/all.fr.tok.60000.pth,,' --para_dataset 'en-fr:,./data/para/dev/newstest2013-ref.XX.60000.pth,./data/para/dev/newstest2014-fren-src.XX.60000.pth' --mono_directions 'en,fr' --word_shuffle 3 --word_dropout 0.1 --word_blank 0.2 --pivo_directions 'fr-en-fr,en-fr-en' --pretrained_emb './data/mono/all.en-fr.60000.vec' --pretrained_out True --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd 1 --otf_num_processes 30 --otf_sync_params_every 1000 --enc_optimizer adam,lr=0.0001 --epoch_size 500000 --stopping_criterion bleu_en_fr_valid,10"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 03/07/19 19:13:30 - 0:00:00 - ============ Initialized logger ============\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - attention: True\n",
            "                                     attention_dropout: 0\n",
            "                                     back_dataset: {}\n",
            "                                     back_directions: []\n",
            "                                     batch_size: 32\n",
            "                                     beam_size: 0\n",
            "                                     clip_grad_norm: 5\n",
            "                                     command: python main.py --exp_name 'test' --transformer 'True' --n_enc_layers '4' --n_dec_layers '4' --share_enc '3' --share_dec '3' --share_lang_emb 'True' --share_output_emb 'True' --langs 'en,fr' --n_mono '-1' --mono_dataset 'en:./data/mono/all.en.tok.60000.pth,,;fr:./data/mono/all.fr.tok.60000.pth,,' --para_dataset 'en-fr:,./data/para/dev/newstest2013-ref.XX.60000.pth,./data/para/dev/newstest2014-fren-src.XX.60000.pth' --mono_directions 'en,fr' --word_shuffle '3' --word_dropout '0.1' --word_blank '0.2' --pivo_directions 'fr-en-fr,en-fr-en' --pretrained_emb './data/mono/all.en-fr.60000.vec' --pretrained_out 'True' --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd '1' --otf_num_processes '30' --otf_sync_params_every '1000' --enc_optimizer 'adam,lr=0.0001' --epoch_size '500000' --stopping_criterion 'bleu_en_fr_valid,10' --exp_id \"crxcyjwtr3\"\n",
            "                                     dec_optimizer: enc_optimizer\n",
            "                                     decoder_attention_heads: 8\n",
            "                                     decoder_normalize_before: False\n",
            "                                     dis_clip: 0\n",
            "                                     dis_dropout: 0\n",
            "                                     dis_hidden_dim: 128\n",
            "                                     dis_input_proj: True\n",
            "                                     dis_layers: 3\n",
            "                                     dis_optimizer: rmsprop,lr=0.0005\n",
            "                                     dis_smooth: 0\n",
            "                                     dropout: 0\n",
            "                                     dump_path: ./dumped/test/crxcyjwtr3\n",
            "                                     emb_dim: 512\n",
            "                                     enc_optimizer: adam,lr=0.0001\n",
            "                                     encoder_attention_heads: 8\n",
            "                                     encoder_normalize_before: False\n",
            "                                     epoch_size: 500000\n",
            "                                     eval_only: False\n",
            "                                     exp_id: crxcyjwtr3\n",
            "                                     exp_name: test\n",
            "                                     freeze_dec_emb: False\n",
            "                                     freeze_enc_emb: False\n",
            "                                     group_by_size: True\n",
            "                                     hidden_dim: 512\n",
            "                                     id2lang: {0: 'en', 1: 'fr'}\n",
            "                                     label_smoothing: 0\n",
            "                                     lambda_dis: 0\n",
            "                                     lambda_lm: 0\n",
            "                                     lambda_xe_back: 0\n",
            "                                     lambda_xe_mono: 0:1,100000:0.1,300000:0\n",
            "                                     lambda_xe_otfa: 0\n",
            "                                     lambda_xe_otfd: 1\n",
            "                                     lambda_xe_para: 0\n",
            "                                     lang2id: {'en': 0, 'fr': 1}\n",
            "                                     langs: ['en', 'fr']\n",
            "                                     length_penalty: 1.0\n",
            "                                     lm_after: 0\n",
            "                                     lm_before: 0\n",
            "                                     lm_share_dec: 0\n",
            "                                     lm_share_emb: False\n",
            "                                     lm_share_enc: 0\n",
            "                                     lm_share_proj: False\n",
            "                                     lstm_proj: False\n",
            "                                     max_epoch: 100000\n",
            "                                     max_len: 175\n",
            "                                     max_vocab: -1\n",
            "                                     mono_dataset: {'en': ('./data/mono/all.en.tok.60000.pth', '', ''), 'fr': ('./data/mono/all.fr.tok.60000.pth', '', '')}\n",
            "                                     mono_directions: ['en', 'fr']\n",
            "                                     n_back: 0\n",
            "                                     n_dec_layers: 4\n",
            "                                     n_dis: 0\n",
            "                                     n_enc_layers: 4\n",
            "                                     n_langs: 2\n",
            "                                     n_mono: -1\n",
            "                                     n_para: 0\n",
            "                                     otf_backprop_temperature: -1\n",
            "                                     otf_num_processes: 30\n",
            "                                     otf_sample: -1\n",
            "                                     otf_sync_params_every: 1000\n",
            "                                     otf_update_dec: True\n",
            "                                     otf_update_enc: True\n",
            "                                     para_dataset: {('en', 'fr'): ('', './data/para/dev/newstest2013-ref.XX.60000.pth', './data/para/dev/newstest2014-fren-src.XX.60000.pth')}\n",
            "                                     para_directions: []\n",
            "                                     pivo_directions: [('fr', 'en', 'fr'), ('en', 'fr', 'en')]\n",
            "                                     pretrained_emb: ./data/mono/all.en-fr.60000.vec\n",
            "                                     pretrained_out: True\n",
            "                                     reload_dec: False\n",
            "                                     reload_dis: False\n",
            "                                     reload_enc: False\n",
            "                                     reload_model: \n",
            "                                     relu_dropout: 0\n",
            "                                     save_periodic: False\n",
            "                                     seed: -1\n",
            "                                     share_dec: 3\n",
            "                                     share_decpro_emb: False\n",
            "                                     share_enc: 3\n",
            "                                     share_encdec_emb: False\n",
            "                                     share_lang_emb: True\n",
            "                                     share_lstm_proj: False\n",
            "                                     share_output_emb: True\n",
            "                                     stopping_criterion: bleu_en_fr_valid,10\n",
            "                                     transformer: True\n",
            "                                     transformer_ffn_emb_dim: 2048\n",
            "                                     vocab: {}\n",
            "                                     vocab_min_count: 0\n",
            "                                     word_blank: 0.2\n",
            "                                     word_dropout: 0.1\n",
            "                                     word_shuffle: 3.0\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - The experiment will be stored in ./dumped/test/crxcyjwtr3\n",
            "                                     \n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - Running command: python main.py --exp_name 'test' --transformer 'True' --n_enc_layers '4' --n_dec_layers '4' --share_enc '3' --share_dec '3' --share_lang_emb 'True' --share_output_emb 'True' --langs 'en,fr' --n_mono '-1' --mono_dataset 'en:./data/mono/all.en.tok.60000.pth,,;fr:./data/mono/all.fr.tok.60000.pth,,' --para_dataset 'en-fr:,./data/para/dev/newstest2013-ref.XX.60000.pth,./data/para/dev/newstest2014-fren-src.XX.60000.pth' --mono_directions 'en,fr' --word_shuffle '3' --word_dropout '0.1' --word_blank '0.2' --pivo_directions 'fr-en-fr,en-fr-en' --pretrained_emb './data/mono/all.en-fr.60000.vec' --pretrained_out 'True' --lambda_xe_mono '0:1,100000:0.1,300000:0' --lambda_xe_otfd '1' --otf_num_processes '30' --otf_sync_params_every '1000' --enc_optimizer 'adam,lr=0.0001' --epoch_size '500000' --stopping_criterion 'bleu_en_fr_valid,10' --exp_id \"crxcyjwtr3\"\n",
            "                                     \n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - ============ Parallel data (en - fr)\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - Loading data from ./data/para/dev/newstest2013-ref.en.60000.pth ...\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - 73141 words (59867 unique) in 3000 sentences. 15 unknown words (4 unique).\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - Loading data from ./data/para/dev/newstest2013-ref.fr.60000.pth ...\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - 119232 words (59867 unique) in 3000 sentences. 1257 unknown words (36 unique).\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - Removed 0 empty sentences.\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - Removed 2 too long sentences.\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - Loading data from ./data/para/dev/newstest2014-fren-src.en.60000.pth ...\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - 81330 words (59867 unique) in 3003 sentences. 24 unknown words (7 unique).\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - Loading data from ./data/para/dev/newstest2014-fren-src.fr.60000.pth ...\n",
            "INFO - 03/07/19 19:13:30 - 0:00:00 - 135087 words (59867 unique) in 3003 sentences. 1235 unknown words (13 unique).\n",
            "INFO - 03/07/19 19:13:30 - 0:00:01 - Removed 0 empty sentences.\n",
            "\n",
            "\n",
            "INFO - 03/07/19 19:13:30 - 0:00:01 - ============ Monolingual data (en)\n",
            "INFO - 03/07/19 19:13:30 - 0:00:01 - Loading data from ./data/mono/all.en.tok.60000.pth ...\n",
            "INFO - 03/07/19 19:13:35 - 0:00:06 - 11916490 words (59867 unique) in 1591855 sentences. 0 unknown words (0 unique).\n",
            "INFO - 03/07/19 19:13:36 - 0:00:06 - Removed 0 empty sentences.\n",
            "INFO - 03/07/19 19:13:36 - 0:00:06 - Removed 295 too long sentences.\n",
            "INFO - 03/07/19 19:13:36 - 0:00:06 - ============ Monolingual data (fr)\n",
            "INFO - 03/07/19 19:13:36 - 0:00:06 - Loading data from ./data/mono/all.fr.tok.60000.pth ...\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - 14814392 words (59867 unique) in 1591855 sentences. 0 unknown words (0 unique).\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Removed 0 empty sentences.\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Removed 405 too long sentences.\n",
            "\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - ============ Data summary\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Parallel data      - valid -   en ->   fr:      2998\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Parallel data      -  test -   en ->   fr:      3003\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Monolingual data   - train -           en:   1591560\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Monolingual data   - valid -           en:         0\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Monolingual data   -  test -           en:         0\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Monolingual data   - train -           fr:   1591450\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Monolingual data   - valid -           fr:         0\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Monolingual data   -  test -           fr:         0\n",
            "\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - ============ Building transformer attention model - Encoder ...\n",
            "INFO - 03/07/19 19:13:42 - 0:00:12 - Sharing encoder input embeddings\n",
            "INFO - 03/07/19 19:13:43 - 0:00:13 - Sharing encoder transformer parameters for layer 1\n",
            "INFO - 03/07/19 19:13:43 - 0:00:13 - Sharing encoder transformer parameters for layer 2\n",
            "INFO - 03/07/19 19:13:43 - 0:00:13 - Sharing encoder transformer parameters for layer 3\n",
            "\n",
            "INFO - 03/07/19 19:13:43 - 0:00:13 - ============ Building transformer attention model - Decoder ...\n",
            "INFO - 03/07/19 19:13:43 - 0:00:13 - Sharing decoder input embeddings\n",
            "INFO - 03/07/19 19:13:44 - 0:00:14 - Sharing decoder transformer parameters for layer 0\n",
            "INFO - 03/07/19 19:13:44 - 0:00:14 - Sharing decoder transformer parameters for layer 1\n",
            "INFO - 03/07/19 19:13:44 - 0:00:14 - Sharing decoder transformer parameters for layer 2\n",
            "INFO - 03/07/19 19:13:45 - 0:00:15 - Sharing decoder projection matrices\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=51 error=38 : no CUDA-capable device is detected\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 356, in <module>\n",
            "    main(params)\n",
            "  File \"main.py\", line 242, in main\n",
            "    encoder, decoder, discriminator, lm = build_mt_model(params, data)\n",
            "  File \"/content/new/UnsupervisedMT/NMT/src/model/__init__.py\", line 98, in build_mt_model\n",
            "    return build_attention_model(params, data, cuda=cuda)\n",
            "  File \"/content/new/UnsupervisedMT/NMT/src/model/attention.py\", line 801, in build_attention_model\n",
            "    encoder.cuda()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 260, in cuda\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 187, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 187, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 193, in _apply\n",
            "    param.data = fn(param.data)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 260, in <lambda>\n",
            "    return self._apply(lambda t: t.cuda(device))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\", line 162, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: cuda runtime error (38) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hi1khhSolKtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c64543d5-6d94-4a27-8215-2bebe474a49c"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4.1 from http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (512.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 512.6MB 43.4MB/s \n",
            "\u001b[31mfastai 1.0.46 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement torch>=1.0.0, but you'll have torch 0.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-0.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d-4_VLi5lY1Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YY9jeDD0m12f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}